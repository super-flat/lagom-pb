play {
  http {
    # In developement this value must be reset
    secret.key = "ahshrefhefjhefeboefvfvofefevelvenv"
    secret.key = ${?APPLICATION_SECRET}
    session {
      secure = false
      sameSite = lax
    }
  }
  server {
    provider = "play.core.server.AkkaHttpServerProvider"
    akka {
      http2 {
        enabled = true
      }
    }
    pidfile {
      path = /dev/null
    }
    http {
      # The default address is all address in case the environment variable PLAY_HTTP_ADDRESS and
      # properties file entry http.address are not found
      address = "0.0.0.0"
      address = ${?HTTP_ADDRESS}
      address = ${?http.address}

      # The default port will be 9000 in case the environment variable PLAY_HTTP_PORT and properties
      # entry http.port are not found
      port = 9000
      port = ${?HTTP_PORT}
      port = ${?http.port}

      # The idle timeout for an open connection after which it will be closed
      # Set to null or "infinite" to disable the timeout, but notice that this
      # is not encouraged since timeout are important mechanisms to protect your
      # servers from malicious attacks or programming mistakes.
      idleTimeout = 75 seconds
    }
  }
  filters {
    enabled += play.filters.cors.CORSFilter
    enabled += play.filters.csrf.CSRFFilter
    enabled += play.filters.headers.SecurityHeadersFilter
    enabled += play.filters.hosts.AllowedHostsFilter

    # CORS config
    cors {
      pathPrefixes = ["/"]
      allowedOrigins = null
      allowedHttpHeaders = null
      # one can define the allowedHttpMethods as follow
      # allowedHttpMethods = ["GET", "POST", "PATCH", "PUT", "DELETE", ...]
      allowedHttpMethods = null
      exposedHeaders = []
      supportsCredentials = true
      preflightMaxAge = 1 hour
      serveForbiddenOrigins = false
    }

    # Allowed hosts filter configuration
    hosts {
      # A list of valid hosts (e.g. "example.com") or suffixes of valid hosts (e.g. ".example.com")
      # Note that ".example.com" will match example.com and any subdomain of example.com, with or without a trailing dot.
      # "." matches all domains, and "" matches an empty or nonexistent host.
      allowed = ["localhost", ".local", "127.0.0.1"]

      routeModifiers {
        # If non empty, then requests will be checked if the route does not have this modifier. This is how we enable the
        # anyhost modifier, but you may choose to use a different modifier (such as "api") if you plan to check the
        # modifier in your code for other purposes.
        whiteList = ["anyhost"]

        # If non empty, then requests will be checked if the route contains this modifier
        # The black list is used only if the white list is empty
        blackList = []
      }
    }

    # CSRF config
    csrf {
      # Token configuration
      token {
        # The token name
        name = "csrfToken"

        # Whether tokens should be signed or not
        sign = true
      }

      # Cookie configuration
      cookie {
        # If non null, the CSRF token will be placed in a cookie with this name
        name = null

        # Whether the cookie should be set to secure
        secure = ${play.http.session.secure}

        # Whether the cookie should have the HTTP only flag set
        httpOnly = false

        # The value of the SameSite attribute of the cookie. Set to null for no SameSite attribute.
        # Possible values are "lax" and "strict". If misconfigured it's set to null.
        sameSite = ${play.http.session.sameSite}
      }

      # How much of the body should be buffered when looking for the token in the request body
      body.bufferSize = ${play.http.parser.maxMemoryBuffer}

      # Bypass the CSRF check if this origin is trusted by the CORS filter
      bypassCorsTrustedOrigins = true

      # Header configuration
      header {

        # The name of the header to accept CSRF tokens from.
        name = "Csrf-Token"


        # Defines headers that must be present to perform the CSRF check. If any of these headers are present, the CSRF
        # check will be performed.
        #
        # By default, we only perform the CSRF check if there are Cookies or an Authorization header.
        # Generally, CSRF attacks use a user's browser to execute requests on the client's behalf. If the user does not
        # have an active session, there is no danger of this happening.
        #
        # Setting this to null or an empty object will protect all requests.
        protectHeaders {
          Cookie = "*"
          Authorization = "*"
        }

        # Defines headers that can be used to bypass the CSRF check if any are present. A value of "*" simply
        # checks for the presence of the header. A string value checks for a match on that string.
        bypassHeaders {}
      }

      # Method lists
      method {
        # If non empty, then requests will be checked if the method is not in this list.
        whiteList = ["GET", "HEAD", "OPTIONS"]

        # The black list is only used if the white list is empty.
        # Only check methods in this list.
        blackList = []
      }

      # Content type lists
      # If both white lists and black lists are empty, then all content types are checked.
      contentType {
        # If non empty, then requests will be checked if the content type is not in this list.
        whiteList = []

        # The black list is only used if the white list is empty.
        # Only check content types in this list.
        blackList = []
      }

      routeModifiers {
        # If non empty, then requests will be checked if the route does not have this modifier. This is how we enable the
        # nocsrf modifier, but you may choose to use a different modifier (such as "api") if you plan to check the
        # modifier in your code for other purposes.
        whiteList = ["nocsrf"]

        # If non empty, then requests will be checked if the route contains this modifier
        # The black list is used only if the white list is empty
        blackList = []
      }

      # The error handler.
      # Used by Play's built in DI support to locate and bind a request handler.  Must be one of the following:
      # - A FQCN that implements play.filters.csrf.CSRF.ErrorHandler (Scala).
      # - A FQCN that implements play.filters.csrf.CSRFErrorHandler (Java).
      # - provided, indicates that the application has bound an instance of play.filters.csrf.CSRF.ErrorHandler through some
      #   other mechanism.
      # If null, will attempt to load a class called CSRFErrorHandler in the root package, otherwise if that's
      # not found, will default to play.filters.csrf.CSRF.CSRFHttpErrorHandler, which delegates to the configured
      # HttpRequestHandler.
      errorHandler = null
    }

    # Security headers filter configuration
    headers {

      # The X-Frame-Options header. If null, the header is not set.
      frameOptions = "DENY"

      # The X-XSS-Protection header. If null, the header is not set.
      xssProtection = "1; mode=block"

      # The X-Content-Type-Options header. If null, the header is not set.
      contentTypeOptions = "nosniff"

      # The X-Permitted-Cross-Domain-Policies header. If null, the header is not set.
      permittedCrossDomainPolicies = "master-only"

      # DEPRECATED: Content Security Policy.  If null, the header is not set.
      # This config property is set to null deliberately as the CSPFilter replaces it.
      contentSecurityPolicy = null

      # The Referrer-Policy header. If null, the header is not set.
      referrerPolicy = "origin-when-cross-origin, strict-origin-when-cross-origin"

      # If true, allow an action to use .withHeaders to replace one or more of the above headers
      allowActionSpecificHeaders = false
    }
  }
}

db {
  default {
    driver = "org.postgresql.Driver"
    username = "postgres"
    username = ${?PERSISTENCE_DB_USER}
    password = "postgres"
    password = ${?PERSISTENCE_DB_PASSWORD}
    host = "localhost"
    host = ${?PERSISTENCE_DB_HOST}
    port = 5432
    port = ${?PERSISTENCE_DB_PORT}
    database = "postgres"
    database = ${?PERSISTENCE_DB_NAME}
    url = "jdbc:postgresql://"${db.default.host}":"${db.default.port}"/"${db.default.database}

    async-executor {
      # number of objects that can be queued by the async executor
      queueSize = 10000

      # 5 * number of cores
      numThreads = 5

      # same as number of threads
      minConnections = 5

      # same as number of threads
      maxConnections = 5

      # if true, a Mbean for AsyncExecutor will be registered
      registerMbeans = false
    }
  }
}

# Defaults to use for each Akka persistence plugin
jdbc-defaults.slick {

  # The Slick profile to use
  # set to one of: slick.jdbc.PostgresProfile$, slick.jdbc.MySQLProfile$, slick.jdbc.OracleProfile$ or slick.jdbc.H2Profile$
  profile = "slick.jdbc.PostgresProfile$"

  async-executor {
    # number of objects that can be queued by the async executor
    queueSize = 10000

    # 5 * number of cores
    numThreads = 5

    # same as number of threads
    minConnections = 5

    # same as number of threads
    maxConnections = 5

    # if true, a Mbean for AsyncExecutor will be registered
    registerMbeans = false
  }

  # Hikari is the default connection pool and it's fine-tuned to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  hikaricp {
    minimumIdle = ${db.default.async-executor.minConnections}
    maximumPoolSize = ${db.default.async-executor.maxConnections}
  }

  # Alternatively, BoneCP can be used instead of Hikari.
  # More information on how to switch to BoneCP can be found here:
  # https://www.playframework.com/documentation/2.6.x/ScalaDatabase#Selecting-and-configuring-the-connection-pool
  #
  # The settings below configured it to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  bonecp {
    # the pool partition count
    partitionCount = 1

    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.minConnections / partitionCount
    minConnectionsPerPartition = ${db.default.async-executor.minConnections}

    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.maxConnections / partitionCount
    maxConnectionsPerPartition = ${db.default.async-executor.maxConnections}
  }
}

lagom {
  persistence {
    jdbc {
      create-tables {
        auto = false
        # How long to wait for tables to be created, before failing
        timeout = 20s

        # The cluster role to create tables from
        run-on-role = ""

        # Exponential backoff for failures configuration for creating tables
        failure-exponential-backoff {

          # minimum (initial) duration until processor is started again
          # after failure
          min = 3s

          # the exponential back-off is capped to this duration
          max = 30s

          # additional random delay is based on this factor
          random-factor = 0.2
        }
      }
    }
  }

  cluster {
    # exit jvm on actor system termination
    # this will allow Kubernetes to restart the pod
    exit-jvm-when-system-terminated = on
    bootstrap {
      enabled = on
    }
  }
}

akka {
  jvm-exit-on-fatal-error = on
  actor {
    serialize-messages = off
    serializers {
      proto = "akka.remote.serialization.ProtobufSerializer"
      cmdSerializer = "io.superflat.lagompb.CommandSerializer"
    }
    serialization-bindings {
      # state is serialized using protobuf
      "scalapb.GeneratedMessage" = proto
      "io.superflat.lagompb.Command" = cmdSerializer
    }
  }

  persistence {
    journal {
      plugin = "jdbc-journal"
    }
    snapshot-store {
      plugin = "jdbc-snapshot-store"
    }
  }

  cluster {
    sharding {
      # Number of shards to be used.
      number-of-shards = 9
    }

    # after 60s of unsuccessul attempts to form a cluster,
    # the actor system will shut down
    shutdown-after-unsuccessful-join-seed-nodes = 60s,

    # Documentation: https://doc.akka.io/docs/akka/current/split-brain-resolver.html#split-brain-resolver
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
    split-brain-resolver {
      # Select one of the available strategies (see descriptions below):
      # static-quorum, keep-majority, keep-oldest, down-all, lease-majority
      # in a Kubernetes environment the Lease strategy can be a good choice.
      active-strategy = keep-majority
      # Time margin after which shards or singletons that belonged to a downed/removed
      # partition are created in surviving partition. The purpose of this margin is that
      # in case of a network partition the persistent actors in the non-surviving partitions
      # must be stopped before corresponding persistent actors are started somewhere else.
      # This is useful if you implement downing strategies that handle network partitions,
      # e.g. by keeping the larger side of the partition and shutting down the smaller side.
      # Decision is taken by the strategy when there has been no membership or
      # reachability changes for this duration, i.e. the cluster state is stable.
      stable-after = 20s
      # When reachability observations by the failure detector are changed the SBR decisions
      # are deferred until there are no changes within the 'stable-after' duration.
      # If this continues for too long it might be an indication of an unstable system/network
      # and it could result in delayed or conflicting decisions on separate sides of a network
      # partition.
      # As a precaution for that scenario all nodes are downed if no decision is made within
      # `stable-after + down-all-when-unstable` from the first unreachability event.
      # The measurement is reset if all unreachable have been healed, downed or removed, or
      # if there are no changes within `stable-after * 2`.
      # The value can be on, off, or a duration.
      # By default it is 'on' and then it is derived to be 3/4 of stable-after.
      down-all-when-unstable = on
    }
  }

  discovery {
    method = akka-dns
  }

  management {
    http {
      # use the pod ip as the host address. This will allow access from outside the pod
      hostname = ${?POD_IP}

      # bind to all interfaces
      bind-hostname = "0.0.0.0"
    }

    cluster {
      bootstrap {
        contact-point-discovery {
          discovery-method = kubernetes-api
          required-contact-point-nr = 1
          required-contact-point-nr = ${?REQUIRED_CONTACT_POINT_NR}
          # Service Name must be defined for production
          service-name = ""
        }
      }
    }
  }

  grpc.client."*" {
    negotiationType = PLAINTEXT
    use-tls = false
  }
}

# custom lagompb settings
lagompb {
  service-name = "lagompb"
  service-name = ${?SERVICE_NAME}

  # Protocol buffers package name to allow lagompb to
  # automatically build a descriptor registry
  protos-package = "io.superflat.lagompb.protobuf.v1"
  protos-package = ${?PROTO_PACKAGE}

  # Ask timeout is required to
  # send commands to the aggregate root and receive response
  # the unit value is in second
  ask-timeout = 5

  snapshot-criteria {
    # number of events to batch persist
    frequency = 100
    frequency = ${?EVENTS_BATCH_THRESHOLD}
    # number of snapshots to retain
    retention = 2
    retention = ${?NUM_SNAPSHOTS_TO_RETAIN}
  }

  events {
    # the events tag name. It is recommended to use the service name
    # because the event tag name must be unique and cannot be changed once the application has handled
    # an aggregate event.
    # Reference: https://www.lagomframework.com/documentation/latest/scala/ReadSide.html#Refactoring-Consideration
    tagname: ${lagompb.service-name}
    tagname: ${?EVENTS_TAG_NAME}
  }
}

kamon {
  trace {
    tick-interval = 1 millisecond
    sampler = always
  }

  propagation.http.default.tags.mappings {
    request-id = "x-request-id"
  }
}
